{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import json\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Leyendo datos desde el archivo CSV en: P:/ETL/Proyecto 3/ETL-Proyect/merged_data (1).csv\n",
      "INFO:root:Tipos de datos del DataFrame:\n",
      "INFO:root:año                             int64\n",
      "nombre_departamento            object\n",
      "Div_dpto                        int64\n",
      "nombre_municipio_x             object\n",
      "Divi_muni                       int64\n",
      "irca_promedio                 float64\n",
      "nombre_parametro_analisis      object\n",
      "numero_parametros_promedio      int64\n",
      "is_top_20                        bool\n",
      "rango_irca                     object\n",
      "tratamiento_categoria          object\n",
      "proporción_crítica            float64\n",
      "clave                          object\n",
      "fecha_proyecto                float64\n",
      "codigo_departamento           float64\n",
      "departamento                   object\n",
      "c_digo_divipola_municipio      object\n",
      "nombre_municipio_y             object\n",
      "indicador                      object\n",
      "nombre_proyecto                object\n",
      "origen                         object\n",
      "estado_seguimiento             object\n",
      "num_municipios                float64\n",
      "región                         object\n",
      "total_financiamiento          float64\n",
      "duracion_proyecto_dias        float64\n",
      "año_proyecto                  float64\n",
      "dtype: object\n",
      "INFO:root:Conectado a la base de datos: water en localhost\n",
      "INFO:root:Insertado año 2018 con ID 13\n",
      "INFO:root:Insertado año 2019 con ID 14\n",
      "INFO:root:Insertado año 2017 con ID 15\n",
      "INFO:root:Insertado ubicación con ID 9\n",
      "INFO:root:Insertado parámetro con ID 9\n",
      "INFO:root:Insertado tratamiento con ID 9\n",
      "INFO:root:Insertado proyecto con ID 9\n",
      "ERROR:root:An error occurred: column \"fecha_proyecto\" is of type date but expression is of type numeric\n",
      "LINE 3: ...              VALUES (15, 9, 9, 9, 9, 6.87, 11, 0.0,  -1.0);\n",
      "                                                                 ^\n",
      "HINT:  You will need to rewrite or cast the expression.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Data loaded successfully'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "def load_data(csv_path, config_path):\n",
    "    \n",
    "    logging.info(f\"Leyendo datos desde el archivo CSV en: {csv_path}\")\n",
    "    df_water = pd.read_csv(csv_path)\n",
    "    df_water.fillna(value=pd.NA, inplace=True)  # Normalizar NaN a NA para compatibilidad con la base de datos\n",
    "\n",
    "    logging.info(\"Tipos de datos del DataFrame:\")\n",
    "    logging.info(df_water.dtypes)\n",
    "\n",
    "    try:\n",
    "        with open(config_path, 'r') as config_json:\n",
    "            config = json.load(config_json)\n",
    "\n",
    "        conx = psycopg2.connect(**config)\n",
    "        cursor = conx.cursor()\n",
    "        logging.info(f\"Conectado a la base de datos: {config['dbname']} en {config['host']}\")\n",
    "\n",
    "        # Insertando en la tabla de dimensión de fechas\n",
    "        for year in df_water['año'].drop_duplicates():\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO dimension_date (\"Año\") VALUES (%s) \n",
    "                ON CONFLICT (\"Año\") DO NOTHING RETURNING \"ID_Tiempo\";\n",
    "            \"\"\", (year,))\n",
    "            id_tiempo = cursor.fetchone()[0] if cursor.rowcount != 0 else None\n",
    "            logging.info(f\"Insertado año {year} con ID {id_tiempo}\")\n",
    "\n",
    "        # Insertando en las demás tablas de dimensión y la tabla de hechos\n",
    "        for _, row in df_water.iterrows():\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO dimension_ubication (\"nombre_departamento\", \"div_dpto\", \"nombre_municipio\", \"divi_muni\") \n",
    "                VALUES (%s, %s, %s, %s) \n",
    "                ON CONFLICT (\"nombre_departamento\", \"div_dpto\", \"nombre_municipio\", \"divi_muni\") DO NOTHING RETURNING \"ID_Ubicacion\";\n",
    "            \"\"\", (row['nombre_departamento'], row['Div_dpto'], row['nombre_municipio_x'], row['Divi_muni']))\n",
    "            id_ubicacion = cursor.fetchone()[0] if cursor.rowcount != 0 else None\n",
    "            logging.info(f\"Insertado ubicación con ID {id_ubicacion}\")\n",
    "\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO dimension_parameters (\"nombre_parametro_analisis\") \n",
    "                VALUES (%s) \n",
    "                ON CONFLICT (\"nombre_parametro_analisis\") DO NOTHING RETURNING \"ID_Parametro\";\n",
    "            \"\"\", (row['nombre_parametro_analisis'],))\n",
    "            id_parametro = cursor.fetchone()[0] if cursor.rowcount != 0 else None\n",
    "            logging.info(f\"Insertado parámetro con ID {id_parametro}\")\n",
    "\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO dimension_tratamiento (\"rango_irca\", \"tratamiento_categoría\") \n",
    "                VALUES (%s, %s) \n",
    "                ON CONFLICT (\"rango_irca\", \"tratamiento_categoría\") DO NOTHING RETURNING \"ID_Rango\";\n",
    "            \"\"\", (row['rango_irca'], row['tratamiento_categoria']))\n",
    "            id_rango = cursor.fetchone()[0] if cursor.rowcount != 0 else None\n",
    "            logging.info(f\"Insertado tratamiento con ID {id_rango}\")\n",
    "\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO dimension_proyecto (\"indicador\", \"nombre_proyecto\", \"origen\", \"estado_seguimiento\", \"num_municipios\", \"region\", \"total_financiamiento\", \"duracion_proyecto_dias\", \"ano_proyecto\") \n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s) \n",
    "                ON CONFLICT (\"indicador\", \"nombre_proyecto\", \"origen\", \"estado_seguimiento\", \"num_municipios\", \"region\", \"total_financiamiento\", \"duracion_proyecto_dias\", \"ano_proyecto\") DO NOTHING RETURNING \"ID_Proyecto\";\n",
    "            \"\"\", (row['indicador'], row['nombre_proyecto'], row['origen'], row['estado_seguimiento'], row['num_municipios'], row['región'], row['total_financiamiento'], row['duracion_proyecto_dias'], row['año_proyecto']))\n",
    "            id_proyecto = cursor.fetchone()[0] if cursor.rowcount != 0 else None\n",
    "            logging.info(f\"Insertado proyecto con ID {id_proyecto}\")\n",
    "\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO Fact_WaterQuality (\"ID_Tiempo\", \"ID_Ubicacion\", \"ID_Parametro\", \"ID_Rango\", \"ID_Proyecto\", \"irca_promedio\", \"numero_parametros_promedio\", \"proporcion_critica\", \"fecha_proyecto\") \n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
    "            \"\"\", (id_tiempo, id_ubicacion, id_parametro, id_rango, id_proyecto, row['irca_promedio'], row['numero_parametros_promedio'], row['proporción_crítica'], row['fecha_proyecto']))\n",
    "            logging.info(f\"Insertado medición con ID_Tiempo {id_tiempo}, ID_Ubicacion {id_ubicacion}, ID_Parametro {id_parametro}, ID_Rango {id_rango}, ID_Proyecto {id_proyecto}\")\n",
    "\n",
    "        conx.commit()\n",
    "        logging.info(\"Los datos se han cargado exitosamente a la base de datos.\")\n",
    "        logging.info(f\"Primeras filas del DataFrame cargado:\\n{df_water.head()}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\")\n",
    "        if 'conx' in locals() and conx:\n",
    "            conx.rollback()\n",
    "    finally:\n",
    "        if 'cursor' in locals() and cursor:\n",
    "            cursor.close()\n",
    "        if 'conx' in locals() and conx:\n",
    "            conx.close()\n",
    "\n",
    "    return \"Data loaded successfully\"\n",
    "\n",
    "# Ruta al archivo CSV y al archivo de configuración\n",
    "csv_path = 'P:/ETL/Proyecto 3/ETL-Proyect/merged_data (1).csv'\n",
    "config_path = 'P:/ETL/Proyecto 3/ETL-Proyect/Airflow_water/db_config.json'\n",
    "\n",
    "# Ejecutar la función\n",
    "load_data(csv_path, config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_water():\n",
    "    with open('./dag_water/db_config.json') as file:\n",
    "        db_config = json.load(file)\n",
    "\n",
    "    engine = create_engine(f'postgresql+psycopg2://{db_config[\"user\"]}:{db_config[\"password\"]}@{db_config[\"host\"]}:3033/{db_config[\"dbname\"]}')\n",
    "\n",
    "    water = pd.read_sql('SELECT * FROM water_table LIMIT 100000', con=engine)\n",
    "\n",
    "    return water.to_json(orient='records')\n",
    "\n",
    "\n",
    "def transform_water(**kwargs):\n",
    "    ti = kwargs['ti']\n",
    "    json_data = json.loads(ti.xcom_pull(task_ids='read_water'))\n",
    "    water = pd.json_normalize(data=json_data)\n",
    "\n",
    "    water = transformations_water(water)\n",
    "\n",
    "    logging.info(\"Datos transformados de agua: %s\", water.to_string())  # Limitar la cantidad de datos logueados si es necesario\n",
    "\n",
    "    return water.to_json(orient='records')\n",
    "\n",
    "\n",
    "\n",
    "def extract_api():\n",
    "    try:\n",
    "        client = Socrata(\"www.datos.gov.co\", None)\n",
    "        results = client.get(\"tcwu-r53g\", limit=2000)\n",
    "        api_data = pd.DataFrame.from_records(results)\n",
    "        print(api_data.shape)\n",
    "        return api_data.to_json(orient='records')\n",
    "    except Exception as e:\n",
    "        logging.error(\"Se produjo un error: %s\", e)\n",
    "\n",
    "\n",
    "\n",
    "def transform_api(**kwargs):\n",
    "    ti = kwargs['ti']\n",
    "\n",
    "    json_data = ti.xcom_pull(task_ids='extract_api')\n",
    "\n",
    "    api = pd.read_json(json_data, orient='records')\n",
    "\n",
    "    api_transformed = transformations_api(api)\n",
    "\n",
    "    logging.info(\"Datos transformados de API: %s\", api_transformed.to_string())\n",
    "\n",
    "    return api_transformed.to_json(orient='records')\n",
    "\n",
    "\n",
    "\n",
    "def expectation_water(**kwargs):\n",
    "    ti = kwargs['ti']\n",
    "    water_json = ti.xcom_pull(task_ids='transform_water')\n",
    "    df_water = pd.read_json(water_json, orient='records')\n",
    "    water_ge = ge.from_pandas(df_water)\n",
    "\n",
    "    logging.info(\"Validating column types\")\n",
    "    water_ge.expect_column_values_to_be_of_type('numero_parametros_promedio', 'int64')\n",
    "    water_ge.expect_column_values_to_be_of_type('irca_promedio', 'float64')\n",
    "    water_ge.expect_column_values_to_be_of_type('nombre_municipio', 'str')\n",
    "    water_ge.expect_column_values_to_be_of_type('nombre_departamento', 'str')\n",
    "    water_ge.expect_column_values_to_be_of_type('año', 'int64')  # Ajustamos a 'int64' porque 'año' es un año extraído como int\n",
    "\n",
    "    logging.info(\"Validating place name normalization\")\n",
    "    water_ge.expect_column_values_to_match_regex('nombre_departamento', r'^[A-Z][a-z]+(?: [A-Z][a-z]+)*$')\n",
    "    water_ge.expect_column_values_to_match_regex('nombre_municipio', r'^[A-Z][a-z]+(?: [A-Z][a-z]+)*$')\n",
    "\n",
    "    logging.info(\"Validating categorical column values\")\n",
    "    water_ge.expect_column_values_to_be_in_set('rango_irca', [\n",
    "        'Sin información', 'Sin riesgo', 'Riesgo bajo',\n",
    "        'Riesgo medio', 'Riesgo alto', 'Riesgo inviable sanitariamente', 'No clasificado'\n",
    "    ])\n",
    "    water_ge.expect_column_values_to_be_in_set('tratamiento_categoria', [\n",
    "        'Sin tratamiento', 'Tratamiento completo', 'Tratamiento parcial'\n",
    "    ])\n",
    "\n",
    "    logging.info(\"Validating scaled values\")\n",
    "    water_ge.expect_column_values_to_be_between('proporción_crítica', 0, 1)\n",
    "\n",
    "    results = water_ge.validate()\n",
    "    logging.info(f\"Validation results: {results}\")\n",
    "\n",
    "    if not results['success']:\n",
    "        logging.error(\"Water data validation failed\")\n",
    "        raise ValueError(\"Water data validation failed\")\n",
    "\n",
    "    return df_water.to_json(orient='records')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def expectation_api(**kwargs):\n",
    "    ti = kwargs['ti']\n",
    "    api_json = ti.xcom_pull(task_ids='transform_api')\n",
    "    df_api = pd.read_json(api_json, orient='records')\n",
    "    api_ge = ge.from_pandas(df_api)\n",
    "\n",
    "    logging.info(\"Validating column types\")\n",
    "    api_ge.expect_column_values_to_be_of_type('nombre_municipio', 'str')\n",
    "    api_ge.expect_column_values_to_be_of_type('fecha_proyecto', 'datetime64[ns]')\n",
    "    api_ge.expect_column_values_to_be_of_type('codigo_departamento', 'int64')\n",
    "    api_ge.expect_column_values_to_be_of_type('num_municipios', 'int64')\n",
    "    api_ge.expect_column_values_to_be_of_type('departamento', 'str')\n",
    "    api_ge.expect_column_values_to_be_of_type('región', 'str')\n",
    "    api_ge.expect_column_values_to_be_of_type('total_financiamiento', 'float64')\n",
    "    api_ge.expect_column_values_to_be_of_type('duracion_proyecto_dias', 'int64')\n",
    "\n",
    "    logging.info(\"Validating place name normalization\")\n",
    "    api_ge.expect_column_values_to_match_regex('departamento', r'^[A-Z ]+$')\n",
    "    api_ge.expect_column_values_to_match_regex('nombre_municipio', r'^[A-Z][a-z]+(?: [A-Z][a-z]+)*$')\n",
    "\n",
    "    logging.info(\"Validating numerical ranges\")\n",
    "    api_ge.expect_column_values_to_be_between('total_financiamiento', 0, 1e9)  # Ajusta según los valores esperados\n",
    "    api_ge.expect_column_values_to_be_between('duracion_proyecto_dias', 0, 1e4)  # Ajusta según los valores esperados\n",
    "\n",
    "    logging.info(\"Remove parentheses validation\")\n",
    "    api_ge.expect_column_values_to_not_match_regex('nombre_municipio', r\"\\(.*?\\)\")\n",
    "\n",
    "    logging.info(\"Space and capitalize validation\")\n",
    "    api_ge.expect_column_values_to_match_regex('nombre_municipio', r'^[A-Z][a-z]+(?: [A-Z][a-z]+)*$')\n",
    "    \n",
    "    results = api_ge.validate()\n",
    "    logging.info(f\"Validation results: {results}\")\n",
    "\n",
    "    return df_api.to_json(orient='records')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def merge_task(**kwargs):\n",
    "    ti = kwargs['ti']\n",
    "\n",
    "    logging.info(\"Recuperando los datos transformados de agua y API desde XCom.\")\n",
    "    # Recuperar los datos transformados de agua y API desde XCom\n",
    "    water_json = ti.xcom_pull(task_ids='expectation_water')\n",
    "    api_json = ti.xcom_pull(task_ids='expectation_api')\n",
    "\n",
    "    logging.info(\"Convirtiendo los datos de JSON a DataFrame.\")\n",
    "    water_cleaned_df = pd.read_json(water_json, orient='records')\n",
    "    api_done_df = pd.read_json(api_json, orient='records')\n",
    "\n",
    "    logging.info(\"Ejecutando la función de merge.\")\n",
    "    # Ejecutar la función de merge\n",
    "    merged_df = merge_datasets(api_done_df, water_cleaned_df)\n",
    "\n",
    "    logging.info(\"Merge completado y datos convertidos a JSON.\")\n",
    "    merged_json = merged_df.to_json(orient='records')\n",
    "    ti.xcom_push(key='merged_data', value=merged_json)  # Push JSON result to XCom\n",
    "    return merged_json\n",
    "\n",
    "def merge_datasets(api_done_df, water_cleaned_df):\n",
    "    logging.info(\"Verificando las columnas disponibles en los DataFrames.\")\n",
    "    logging.info(f\"Columnas en water_cleaned_df: {list(water_cleaned_df.columns)}\")\n",
    "    logging.info(f\"Columnas en api_done_df: {list(api_done_df.columns)}\")\n",
    "    \n",
    "    logging.info(\"Asegurando que las columnas son de tipo string y año como int.\")\n",
    "    water_cleaned_df['año'] = water_cleaned_df['año'].astype(int)\n",
    "    water_cleaned_df['nombre_departamento'] = water_cleaned_df['nombre_departamento'].astype(str)\n",
    "    water_cleaned_df['nombre_municipio'] = water_cleaned_df['nombre_municipio'].astype(str)\n",
    "\n",
    "    api_done_df['fecha_proyecto'] = pd.to_datetime(api_done_df['fecha_proyecto'], errors='coerce')\n",
    "    api_done_df['codigo_departamento'] = api_done_df['codigo_departamento'].astype(str)\n",
    "    api_done_df['departamento'] = api_done_df['departamento'].astype(str)\n",
    "    api_done_df['nombre_municipio'] = api_done_df['nombre_municipio'].astype(str)\n",
    "    api_done_df['año_proyecto'] = api_done_df['fecha_proyecto'].dt.year\n",
    "\n",
    "    logging.info(\"Filtrando los DataFrames para incluir solo los años 2017, 2018 y 2019.\")\n",
    "    water_cleaned_df = water_cleaned_df[water_cleaned_df['año'].isin([2017, 2018, 2019])]\n",
    "    api_done_df = api_done_df[api_done_df['año_proyecto'].isin([2017, 2018, 2019])]\n",
    "\n",
    "    logging.info(\"Creando claves únicas para el merge.\")\n",
    "    water_cleaned_df['clave'] = (water_cleaned_df['nombre_departamento'].str.lower().str.strip() + \"_\" +\n",
    "                                 water_cleaned_df['nombre_municipio'].str.lower().str.strip() + \"_\" +\n",
    "                                 water_cleaned_df['año'].astype(str))\n",
    "\n",
    "    api_done_df['clave'] = (api_done_df['departamento'].str.lower().str.strip() + \"_\" +\n",
    "                            api_done_df['nombre_municipio'].str.lower().str.strip() + \"_\" +\n",
    "                            api_done_df['año_proyecto'].astype(str))\n",
    "\n",
    "    logging.info(f\"Claves únicas en water_cleaned_df:\\n{water_cleaned_df['clave'].unique()}\")\n",
    "    logging.info(f\"Claves únicas en api_done_df:\\n{api_done_df['clave'].unique()}\")\n",
    "\n",
    "\n",
    "    logging.info(\"Realizando el merge de los datasets.\")\n",
    "    merged_df = pd.merge(water_cleaned_df, api_done_df, on='clave', how='outer')\n",
    "\n",
    "    logging.info(\"Llenando valores faltantes con valores predeterminados.\")\n",
    "    merged_df.fillna({\n",
    "        'fecha_proyecto': '1971-01-01', 'codigo_departamento': '-1', 'departamento': 'Desconocido',\n",
    "        'nombre_municipio': 'Desconocido', 'indicador': '-1', 'nombre_proyecto': 'Desconocido',\n",
    "        'origen': 'Desconocido', 'estado_seguimiento': 'Desconocido', 'num_municipios': -1,\n",
    "        'región': 'Desconocido', 'total_financiamiento': -1.0, 'duracion_proyecto_dias': -1.0,\n",
    "        'año_proyecto': -1\n",
    "    }, inplace=True)\n",
    "\n",
    "    logging.info(f\"El DataFrame combinado tiene {merged_df.shape[0]} filas y {merged_df.shape[1]} columnas.\")\n",
    "    logging.info(f\"Primeras filas del DataFrame combinado:\\n{merged_df.head()}\")\n",
    "    logging.info(f\"Número de proyectos únicos: {merged_df['nombre_proyecto'].nunique()}\")\n",
    "    logging.info(f\"Años presentes en los datos combinados: {merged_df['año'].unique()}\")\n",
    "    logging.info(f\"Tipos de datos de las columnas:\\n{merged_df.dtypes}\")\n",
    "\n",
    "\n",
    "\n",
    "    csv_path = '/root/airflow_water12/dag_water/merged_data.csv'\n",
    "    merged_df.to_csv(csv_path, index=False)\n",
    "    logging.info(f\"Archivo CSV guardado en: {csv_path}\")\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load(**kwargs):\n",
    "    csv_path = '/root/airflow_water12/dag_water/merged_data.csv'\n",
    "    db_config_path = '/root/airflow_water12/dag_water/db_config.json'\n",
    "\n",
    "    logging.info(f\"Leyendo datos desde el archivo CSV en: {csv_path}\")\n",
    "\n",
    "    df_water = pd.read_csv(csv_path)\n",
    "    df_water.fillna(value=pd.NA, inplace=True)  # Normalizar NaN a NA para compatibilidad con la base de datos\n",
    "\n",
    "    try:\n",
    "        with open(db_config_path, 'r') as config_json:\n",
    "            db_config = json.load(config_json)\n",
    "            conx = psycopg2.connect(**db_config)\n",
    "            cursor = conx.cursor()\n",
    "\n",
    "            # Mostrar la base de datos y la ubicación\n",
    "            logging.info(f\"Conectado a la base de datos: {db_config['dbname']} en {db_config['host']}\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Creación de tablas de dimensiones y tabla de hechos con restricciones únicas\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS dimension_date (\n",
    "                    \"ID_Tiempo\" SERIAL PRIMARY KEY,\n",
    "                    \"Año\" INT NOT NULL UNIQUE\n",
    "                );\n",
    "            \"\"\")\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS dimension_ubication (\n",
    "                    \"ID_Ubicacion\" SERIAL PRIMARY KEY,\n",
    "                    \"nombre_departamento\" VARCHAR(255) NOT NULL,\n",
    "                    \"div_dpto\" INT NOT NULL,\n",
    "                    \"nombre_municipio\" VARCHAR(255) NOT NULL,\n",
    "                    \"divi_muni\" INT NOT NULL,\n",
    "                    UNIQUE (\"nombre_departamento\", \"div_dpto\", \"nombre_municipio\", \"divi_muni\")\n",
    "                );\n",
    "            \"\"\")\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS dimension_parameters (\n",
    "                    \"ID_Parametro\" SERIAL PRIMARY KEY,\n",
    "                    \"nombre_parametro_analisis\" VARCHAR(255) NOT NULL UNIQUE\n",
    "                );\n",
    "            \"\"\")\n",
    "            \n",
    "            \n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS dimension_tratamiento (\n",
    "                    \"ID_Rango\" SERIAL PRIMARY KEY,\n",
    "                    \"rango_irca\" VARCHAR(255) NOT NULL,\n",
    "                    \"tratamiento_categoría\" VARCHAR(255) NOT NULL,\n",
    "                    UNIQUE (\"rango_irca\", \"tratamiento_categoría\")\n",
    "                );\n",
    "            \"\"\")\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS dimension_proyecto (\n",
    "                    \"ID_Proyecto\" SERIAL PRIMARY KEY,\n",
    "                    \"indicador\" VARCHAR(255) NOT NULL,\n",
    "                    \"nombre_proyecto\" VARCHAR(255) NOT NULL,\n",
    "                    \"origen\" VARCHAR(255) NOT NULL,\n",
    "                    \"estado_seguimiento\" VARCHAR(255) NOT NULL,\n",
    "                    \"num_municipios\" INT NOT NULL,\n",
    "                    \"region\" VARCHAR(255) NOT NULL,\n",
    "                    \"total_financiamiento\" FLOAT NOT NULL,\n",
    "                    \"duracion_proyecto_dias\" INT NOT NULL,\n",
    "                    \"ano_proyecto\" INT NOT NULL,\n",
    "                    UNIQUE (\"indicador\", \"nombre_proyecto\", \"origen\", \"estado_seguimiento\", \"num_municipios\", \"region\", \"total_financiamiento\", \"duracion_proyecto_dias\", \"ano_proyecto\")\n",
    "                );\n",
    "            \"\"\")\n",
    "            \n",
    "            \n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS Fact_WaterQuality (\n",
    "                    \"ID_Medicion\" SERIAL PRIMARY KEY,\n",
    "                    \"ID_Tiempo\" INT NOT NULL REFERENCES dimension_date(\"ID_Tiempo\"),\n",
    "                    \"ID_Ubicacion\" INT NOT NULL REFERENCES dimension_ubication(\"ID_Ubicacion\"),\n",
    "                    \"ID_Parametro\" INT NOT NULL REFERENCES dimension_parameters(\"ID_Parametro\"),\n",
    "                    \"ID_Rango\" INT NOT NULL REFERENCES dimension_tratamiento(\"ID_Rango\"),\n",
    "                    \"ID_Proyecto\" INT NOT NULL REFERENCES dimension_proyecto(\"ID_Proyecto\"),\n",
    "                    \"irca_promedio\" FLOAT NOT NULL,\n",
    "                    \"numero_parametros_promedio\" INT NOT NULL,\n",
    "                    \"proporcion_critica\" FLOAT NOT NULL,\n",
    "                    \"fecha_proyecto\" DATE NOT NULL\n",
    "                );\n",
    "            \"\"\")\n",
    "\n",
    "            conx.commit()\n",
    "            logging.info(\"Tablas creadas exitosamente.\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            for year in df_water['año'].drop_duplicates():\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO dimension_date (\"Año\") VALUES (%s) ON CONFLICT (\"Año\") DO NOTHING RETURNING \"ID_Tiempo\";\n",
    "                \"\"\", (year,))\n",
    "                id_tiempo = cursor.fetchone()[0] if cursor.rowcount != 0 else None\n",
    "                logging.info(f\"Insertado año {year} con ID {id_tiempo}\")\n",
    "\n",
    "            for _, row in df_water.iterrows():\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO dimension_ubication (\"nombre_departamento\", \"div_dpto\", \"nombre_municipio\", \"divi_muni\")                    VALUES (%s, %s, %s, %s) ON CONFLICT (\"nombre_departamento\", \"div_dpto\", \"nombre_municipio\", \"divi_muni\") DO NOTHING RETURNING \"ID_Ubicacion\";\n",
    "                \"\"\", (row['nombre_departamento'], row['Div_dpto'], row['nombre_municipio_x'], row['Divi_muni']))\n",
    "                id_ubicacion = cursor.fetchone()[0] if cursor.rowcount != 0 else None\n",
    "                logging.info(f\"Insertado ubicación con ID {id_ubicacion}\")\n",
    "\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO dimension_parameters (\"nombre_parametro_analisis\")\n",
    "                    VALUES (%s) ON CONFLICT (\"nombre_parametro_analisis\") DO NOTHING RETURNING \"ID_Parametro\";\n",
    "                \"\"\", (row['nombre_parametro_analisis'],))\n",
    "                id_parametro = cursor.fetchone()[0] if cursor.rowcount != 0 else None\n",
    "                logging.info(f\"Insertado parámetro con ID {id_parametro}\")\n",
    "\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO dimension_tratamiento (\"rango_irca\", \"tratamiento_categoría\")\n",
    "                    VALUES (%s, %s) ON CONFLICT (\"rango_irca\", \"tratamiento_categoría\") DO NOTHING RETURNING \"ID_Rango\";                \"\"\", (row['rango_irca'], row['tratamiento_categoria']))\n",
    "                id_rango = cursor.fetchone()[0] if cursor.rowcount != 0 else None\n",
    "                \n",
    "                \n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO dimension_tratamiento (\"rango_irca\", \"tratamiento_categoría\")\n",
    "                    VALUES (%s, %s) ON CONFLICT (\"rango_irca\", \"tratamiento_categoría\") DO NOTHING RETURNING \"ID_Rango\";\n",
    "                \"\"\", (row['rango_irca'], row['tratamiento_categoria']))\n",
    "                id_rango = cursor.fetchone()[0] if cursor.rowcount != 0 else None\n",
    "                logging.info(f\"Insertado tratamiento con ID {id_rango}\")\n",
    "\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO dimension_proyecto (\"indicador\", \"nombre_proyecto\", \"origen\", \"estado_seguimiento\", \"num_municipios\", \"region\", \"total_financiamiento\", \"duracion_proyecto_dias\", \"ano_proyecto\")\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s) ON CONFLICT (\"indicador\", \"nombre_proyecto\", \"origen\", \"estado_seguimiento\", \"num_municipios\", \"region\", \"total_financiamiento\", \"duracion_proyecto_dias\", \"ano_proyecto\") DO NOTHING RETURNING \"ID_Proyecto\";\n",
    "                \"\"\", (row['indicador'], row['nombre_proyecto'], row['origen'], row['estado_seguimiento'], row['num_municipios'], row['región'], row['total_financiamiento'], row['duracion_proyecto_dias'], row['año_proyecto']))\n",
    "                id_proyecto = cursor.fetchone()[0] if cursor.rowcount != 0 else None\n",
    "                logging.info(f\"Insertado proyecto con ID {id_proyecto}\")\n",
    "\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO Fact_WaterQuality (\"ID_Tiempo\", \"ID_Ubicacion\", \"ID_Parametro\", \"ID_Rango\", \"ID_Proyecto\", \"irca_promedio\", \"numero_parametros_promedio\", \"proporcion_critica\", \"fecha_proyecto\")\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
    "                \"\"\", (id_tiempo, id_ubicacion, id_parametro, id_rango, id_proyecto, row['irca_promedio'], row['numero_parametros_promedio'], row['proporción_crítica'], row['fecha_proyecto']))\n",
    "                logging.info(f\"Insertado medición con ID_Tiempo {id_tiempo}, ID_Ubicacion {id_ubicacion}, ID_Parametro {id_parametro}, ID_Rango {id_rango}, ID_Proyecto {id_proyecto}\")\n",
    "\n",
    "            conx.commit()\n",
    "            logging.info(\"Los datos se han cargado exitosamente a la base de datos.\")\n",
    "            logging.info(\"Los datos se han cargado exitosamente a la base de datos.\")\n",
    "            logging.info(f\"Primeras filas del DataFrame cargado:\\n{df_water.head()}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\")\n",
    "        if 'conx' in locals() and conx:\n",
    "            conx.rollback()\n",
    "    finally:\n",
    "        if 'cursor' in locals() and cursor:\n",
    "            cursor.close()\n",
    "        if 'conx' in locals() and conx:\n",
    "            conx.close()\n",
    "\n",
    "    return \"Data loaded successfully\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
